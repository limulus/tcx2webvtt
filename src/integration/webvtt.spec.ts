// import { page } from '@vitest/browser/context'
import { test, expect } from 'vitest'

import { Coordinates, SampleMetric } from '../lib/sample.js'
import { SequentialCueGenerator } from '../lib/sequential-cue-generator.js'
import { TCXReader } from '../lib/tcx-reader.js'
import { WebVTTGenerator } from '../lib/webvtt-generator.js'

/**
 * This test file verifies that the WebVTT files generated by our library
 * are properly parsed and rendered by actual browser implementations.
 */
test('browser should be able to read WebVTT generated by tcx2webvtt', async () => {
  const tcxData = await fetch('/fixtures/tcx/healthkit-cycling.tcx').then((res) =>
    res.text()
  )
  const tcxReader = new TCXReader(tcxData)
  const samples = tcxReader.getSamples()
  expect(samples.length).toBeGreaterThan(0)

  // Limit to just 5 samples for this test
  const limitedSamples = samples.slice(0, 5)

  // Generate sequential cues from samples
  const cueGenerator = new SequentialCueGenerator()
  const generatedCues = cueGenerator.generateCues(limitedSamples)

  const webVTT = new WebVTTGenerator()
  const vttData = webVTT.generate(generatedCues)
  const vttBlob = new Blob([vttData], { type: 'text/vtt' })
  const vttUrl = URL.createObjectURL(vttBlob)

  // Create a video element (audio elements have inconsistent support for tracks)
  const videoElement = document.createElement('video')
  videoElement.setAttribute('data-testid', 'video')

  // Create a track element for our WebVTT data
  const trackElement = document.createElement('track')
  trackElement.kind = 'metadata'
  trackElement.default = true
  trackElement.src = vttUrl

  videoElement.appendChild(trackElement)
  document.body.appendChild(videoElement)

  // Add fake video source
  const emptyVideoBlob = new Blob([new Uint8Array(10)], { type: 'video/mp4' })
  const videoUrl = URL.createObjectURL(emptyVideoBlob)
  videoElement.src = videoUrl

  // Wait for the video and track to load
  await new Promise<void>((resolve, reject) => {
    const timeout = setTimeout(() => {
      reject(new Error('Load event on track element timed out'))
    }, 1000)

    trackElement.addEventListener('load', () => {
      clearTimeout(timeout)
      resolve()
    })
  })

  // Ensure the track was created and is available
  const metadataTrack = videoElement.textTracks[0]
  expect(metadataTrack).toBeDefined()
  expect(metadataTrack.kind).toBe('metadata')

  // Verify we have the expected cues
  const cues = metadataTrack.cues
  expect(cues).toBeDefined()
  expect(cues?.length).toBe(limitedSamples.length)

  // Verify the contents of each cue
  for (let i = 0; i < cues!.length; i++) {
    const cue = cues![i] as VTTCue
    const sample = limitedSamples[i]

    expect(cue).toBeDefined()

    // Check timing matches our expected pattern (SequentialCueGenerator uses 1-second intervals)
    expect(cue.startTime).toBe(i)
    expect(cue.endTime).toBe(i + 1)

    // Test actual cue content matches expected format (cue contains array of samples)
    const cueText = cue.text
    const parsedCueData = JSON.parse(cueText)

    // Each cue contains an array with one sample
    expect(Array.isArray(parsedCueData)).toBe(true)
    expect(parsedCueData).toHaveLength(1)

    const sampleData = parsedCueData[0]
    expect(sampleData.metric).toBe(sample.metric)

    if (sample.metric === SampleMetric.Location) {
      const location = sample.value as Coordinates
      expect(sampleData.value.latitude).toBe(location.latitude)
      expect(sampleData.value.longitude).toBe(location.longitude)
      if (location.altitude !== undefined) {
        expect(sampleData.value.altitude).toBe(location.altitude)
      }
    } else {
      expect(sampleData.value).toBe(sample.value)
    }
  }
})
